本赛题采用标准 检索增强生成（RAG）架构，流程如下：
检索：使用 intfloat/e5-large-v2 对输入问题编码；
在预构建的 FAISS 索引（基于 Wiki18 100万文档）中执行 ANN 搜索；
返回 Top-3 最相关文档片段作为上下文。
增强：将检索到的文档内容拼接为“资料”段落；与原始问题组合成结构化 Prompt，明确指示模型“仅输出答案”。
生成：由本地部署的 Qwen2.5-32B 模型基于增强后的 Prompt 生成回答；采用确定性解码（temperature=0.0, do_sample=False）确保结果稳定。
后处理：仅对极少数仍含模板前缀的输出进行正则清洗；不截断语义、不强制字数限制，保留模型原始判断。

系统整体设计：基于 FlashRAG 框架，设计并实现了一个端到端的智能 DeepSearch 问答系统，涵盖检索、生成与后处理全流程。
环境配置与依赖管理：将本地 FlashRAG 库正确接入 Python 路径，确保在指定服务器环境下顺利调用 Qwen2.5-32B 大模型及 e5 检索器。
自定义生成器开发：继承 HFCausalLMGenerator 类，重写 _build_prompt 方法，构建极简指令式提示（prompt），强制模型仅输出答案本身，避免冗余解释。
答案后处理模块：编写 clean_answer 函数，通过正则表达式自动去除模型输出中的引导语（如“答案是”“根据资料”等）、引号、多余空格，并截取第一句核心内容，确保输出简洁规范。
主流程实现与异常处理：完成从读取输入文件（data_b.json）、逐条问题推理、结果收集到写入标准输出格式（result_b.jsonl）的完整 pipeline，并加入异常捕获机制，保障程序鲁棒性。
参数调优：设置 retrieval_topk=3 控制检索文档数量以平衡信息覆盖与噪声干扰；采用 max_new_tokens=96、temperature=0.0、do_sample=False 等参数确保生成结果确定、简洁且聚焦。
系统调试与部署：解决因磁盘空间不足导致的配置初始化失败问题（通过理解 FlashRAG 默认行为并调整运行环境），确保系统稳定高效运行。
